entries:
  - term: "AI-Enabled Problem Solving"
    definition: "A three-phase methodology for diagnosing operational problems, prioritizing solutions, and sustaining improvements using Agile governance. Rests on two foundational principles: Data First and AI First."
    first_lesson: "04-introducing-aomt"

  - term: "Data First"
    definition: "The principle of ingesting and interrogating comprehensive data before proposing solutions. Instead of starting with stakeholder impressions, start with data patterns and validate them against stakeholder experience."
    first_lesson: "04-introducing-aomt"

  - term: "AI First"
    definition: "The principle of designing solutions that take full advantage of AI capabilities to achieve quantum gains in efficiency. Ask 'what becomes possible if AI handles this?' rather than 'how can AI speed up step 3?'"
    first_lesson: "04-introducing-aomt"

  - term: "Problem Statement"
    definition: "Structured format defining the problem being solved. Contains seven components: Description, Customers, Decision Makers, Decision Drivers, Boundaries, Success Measures, and Timeframe."
    first_lesson: "03-problem-statement"

  - term: "Issues Tree"
    definition: "A structured MECE decomposition tool that breaks a problem into logical component parts. Depicted horizontally with trunk (main problem), branches, sub-branches, and twigs."
    first_lesson: "04-issues-tree-and-hypotheses"

  - term: "Hypothesis Testing"
    definition: "Scientific method applied to operational problems using Null Hypothesis (H0: no effect) and Alternative Hypothesis (Ha: no effect cannot be proven). Rejecting H0 means the factor warrants investigation, not that causation is proven."
    first_lesson: "04-issues-tree-and-hypotheses"

  - term: "Validated Gap"
    definition: "The measured difference between current performance and a benchmark, confirmed by both quantitative data and qualitative interviews. A gap in data but not interviews (or vice versa) is a hypothesis, not validated."
    first_lesson: "09-analysis-validation"

  - term: "Baseline"
    definition: "The pre-implementation measurement used as a reference point. Must be specific, measured, and documented before any solution is implemented."
    first_lesson: "09-analysis-validation"

  - term: "Benchmark"
    definition: "An external or industry-standard reference point used to assess whether a gap is significant. Answers the question 'compared to what?'"
    first_lesson: "10-ai-enabled-research"

  - term: "Root Cause vs. Symptom"
    definition: "A root cause is the mechanism producing the observed problem. A symptom is the problem itself. Phase 1 requires root causes, not symptoms."
    first_lesson: "09-analysis-validation"

  - term: "Drift"
    definition: "Gradual, unintended regression of a metric toward its pre-implementation baseline. Dangerous because it is gradual and compounds over time."
    first_lesson: "01-sustainment-framework"

  - term: "WSJF"
    definition: "Weighted Shortest Job First. Phase 2 scoring method: Cost of Delay / Job Size = WSJF Score. Cost of Delay = Business Value + Time Criticality + Risk Reduction & Opportunity Enablement."
    first_lesson: "03-wsjf-scoring-method"

  - term: "Business Value"
    definition: "A 1-10 rating of business value an option delivers. Scored by the cross-functional team. Common error: confusing effort required with value delivered."
    first_lesson: "03-wsjf-scoring-method"

  - term: "Time Criticality"
    definition: "A 1-10 rating of urgency. Higher scores indicate regulatory deadlines, competitive pressure, or customer attrition risk."
    first_lesson: "03-wsjf-scoring-method"

  - term: "Risk Reduction & Opportunity Enablement"
    definition: "A 1-10 rating of organizational risk mitigated or future capabilities unlocked by implementing the option."
    first_lesson: "03-wsjf-scoring-method"

  - term: "Job Size"
    definition: "A 1-10 rating of implementation duration and complexity. The divisor in WSJF, so high-effort options need proportionally higher value to justify ranking."
    first_lesson: "03-wsjf-scoring-method"

  - term: "Context + Task + Output"
    definition: "The prompt structure used throughout the methodology for AI interactions. Context provides validated findings, Task specifies what AI should produce, Output defines the format."
    first_lesson: "07-curiosity-enabled-analysis"

  - term: "Sequential Prompting"
    definition: "Breaking a complex ask into multiple turns rather than one prompt. Each turn lets the practitioner check output before it becomes input for the next step."
    first_lesson: "11-data-analysis-plan"

  - term: "Hallucination"
    definition: "When an AI model generates factually wrong but structurally plausible text. LLMs produce statistically likely text, not verified facts. The methodology treats all AI-generated figures as unverified until checked."
    first_lesson: "09-analysis-validation"

  - term: "Sensitivity Analysis"
    definition: "Asking AI to generate scenarios when assumptions change. Best/likely/worst case. The scenarios are useful framing; specific numbers require independent verification."
    first_lesson: "10-ai-enabled-research"

  - term: "Agentic Tool"
    definition: "An AI system that performs tasks autonomously within defined parameters, planning steps, executing actions, and adapting based on results without requiring human direction at each stage."
    first_lesson: "01-ai-tool-development"

  - term: "Epic"
    definition: "A high-level capability encompassing multiple user stories. Epics correspond to major solution components that can be estimated, prioritized, and implemented independently."
    first_lesson: "02-design-and-prototype"

  - term: "User Story"
    definition: "A specific need from a user perspective: 'As a [role], I want [capability] so that [benefit].' Describes user experience, not system architecture."
    first_lesson: "02-design-and-prototype"

  - term: "Sprint"
    definition: "A fixed-duration work cycle, typically two weeks. During Phase 3, feedback becomes backlog items prioritized and committed to sprints."
    first_lesson: "04-safe-framework"

  - term: "Product Owner / Product Manager"
    definition: "Person who owns the product backlog and prioritization decisions. Reviews AI feedback analysis weekly and creates backlog items for sprint planning."
    first_lesson: "04-safe-framework"

  - term: "Product Backlog"
    definition: "The ordered list of all work items for a solution, maintained by the Product Owner / Product Manager. Grows from tech feedback, metric signals, and stakeholder observations."
    first_lesson: "04-safe-framework"

  - term: "Option Set"
    definition: "The 2-4 solution options developed in Phase 1 for Phase 2 scoring. Must contain genuine trade-offs between speed, impact, risk, and cost."
    first_lesson: "12-opportunity-synthesis"

  - term: "Quick Win"
    definition: "A low-risk, low-investment option implementable in weeks. Required in every option set. Trades magnitude for certainty."
    first_lesson: "12-opportunity-synthesis"

  - term: "Transformational Option"
    definition: "A high-impact, high-investment option requiring months. Carries the most fragile assumptions. Verify with IT and procurement before presenting."
    first_lesson: "12-opportunity-synthesis"

  - term: "Sustainment Framework"
    definition: "Three-pillar model: Structure (reporting lines, incentives), Support (continuous learning, collaboration), Feedback (goal setting, performance scorecards). All three must be present."
    first_lesson: "01-sustainment-framework"

  - term: "Feedback Loop"
    definition: "Structured mechanism where field observations reach someone who can act within a defined timeframe. Has a source, cadence, owner, and connection to sprint backlog."
    first_lesson: "04-feedback-performance"

  - term: "Agile Governance"
    definition: "Post-implementation management where the solution evolves continuously through sprint cycles based on user feedback. Assumes initial implementation is Version 1."
    first_lesson: "04-feedback-performance"

  - term: "Readiness Baseline"
    definition: "Initial assessment across three dimensions: North Star Vision, Performance Management alignment, and Resource availability."
    first_lesson: "01-change-readiness-baseline"

  - term: "Readiness Assessment"
    definition: "Evaluation of organizational capacity to absorb change across: Case for Change, Influence Network, and Communications."
    first_lesson: "02-readiness-assessment"

  - term: "Case for Change"
    definition: "The articulated answer to 'why are we doing this?' that must resonate at every level. Must name specific harm of current state and concrete benefit of proposed change."
    first_lesson: "02-readiness-assessment"

  - term: "Influence Network"
    definition: "Map of who actually shapes opinion and drives adoption, which rarely matches the org chart. Includes formal leaders, informal leaders, and resistors."
    first_lesson: "02-readiness-assessment"

  - term: "Monitoring Cadence"
    definition: "How often metrics are checked: daily (zone-level), weekly (feedback analysis), monthly (trends), quarterly (solution health). Too frequent creates alert fatigue; too infrequent allows drift."
    first_lesson: "04-feedback-performance"

  - term: "Agile"
    definition: "An iterative approach to software development and project delivery that emphasizes short cycles, continuous feedback, and adaptive planning. Agile teams deliver working increments in 2-week sprints, enabling rapid course correction based on real user feedback rather than upfront speculation."
    first_lesson: "04-safe-framework"

  - term: "Diagnostic Interviews"
    definition: "Early Phase 1 interviews asking 'What is broken? What frustrates you?' to generate qualitative data that combines with quantitative data to validate gaps."
    first_lesson: "09-analysis-validation"

  - term: "Validation Interviews"
    definition: "Post-solution interviews testing whether proposed solutions address described problems. Different from diagnostic interviews. If interviews contradict the solution, the solution is wrong."
    first_lesson: "09-analysis-validation"

  - term: "Confirmation Bias"
    definition: "Tendency to interpret evidence as confirmation of existing beliefs. Particularly dangerous during validation interviews. Defense: open-ended questions, treat contradictions as signal."
    first_lesson: "09-analysis-validation"

  - term: "T-Shirt Sizing"
    definition: "Rough effort estimation using S/M/L/XL. S=days, M=weeks, L=1-3 months, XL=3+ months. False precision is worse than acknowledged imprecision at Phase 1 stage."
    first_lesson: "03-wsjf-scoring-method"

  - term: "MECE"
    definition: "Mutually Exclusive, Collectively Exhaustive. A structuring principle for issues trees ensuring that categories don't overlap and together cover all possibilities."
    first_lesson: "04-issues-tree-and-hypotheses"

  - term: "System of Record"
    definition: "The authoritative data source for a given dataset. When requesting data, identifying the system of record ensures you receive the most accurate and current version of the data."
    first_lesson: "05-data-request-and-ingestion"

  - term: "BI Tools"
    definition: "Business Intelligence tools used for data visualization and reporting. Traditional BI tools require manual data preparation and configuration; AI-enabled approaches can generate equivalent visualizations in seconds through natural language prompting."
    first_lesson: "06-data-visualization"

  - term: "Fibonacci Sequence"
    definition: "A number sequence (1, 2, 3, 5, 8, 13...) used in Agile estimation and WSJF scoring to force meaningful differentiation between items. The increasing gaps between values prevent false precision in relative sizing."
    first_lesson: "03-wsjf-scoring-method"
